# LlmPractice

All inspiration for this project came from: https://medium.com/scrum-and-coke/creating-a-web-api-with-net-9-to-interact-with-a-local-ollama-ai-instance-using-llama-3-1-41fcc3cceb8b

Already quite a bit had changed from the writing of that article though regarding the Microsoft.Extensions.AI package.

Requires .NET 9, Docker running ollama llama3.1 on port 11434

Watch a demo video here: 
(Jump ahead to 40 seconds after I first type in hello, quick loading will be fixed in V2)
[![IMAGE ALT TEXT HERE](https://img.youtube.com/vi/KcARRbxvsKY/0.jpg)](https://www.youtube.com/watch?v=KcARRbxvsKY)
