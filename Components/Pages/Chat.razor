@rendermode InteractiveServer
@page "/chat"
@using LlmPractice.Models
@using Microsoft.Extensions.AI
@inject HttpClient Http

<!-- Model selection dropdown -->
<div class="model-selection mb-2">
    <label for="modelSelect">Select Model:</label>
    <select id="modelSelect" @bind="_selectedModel" class="form-select">
        <option value="llama3.1:8b">Llama 3.1 (8b)</option>
        <option value="llama2:7b">Llama 2 (7b)</option>
    </select>
</div>

<div class="chat-container" style="display: flex; flex-direction: column; height: 80vh; border: 1px solid #ccc; padding: 10px;">

    <!-- Chat history -->
    <div class="chat-history" style="flex: 1; overflow-y: auto; margin-bottom: 10px;">
        <h4>Chat History</h4>
        <ul class="list-group">
            @foreach (ChatMessageDisplay msg in _chatHistory)
            {
                <li class="list-group-item">
                    <strong>@(msg.Role.Equals("Assistant", StringComparison.OrdinalIgnoreCase) ? "Assistant" : msg.Role):</strong> @msg.Message
                </li>
            }
        </ul>
    </div>

    <!-- Spinner while waiting for response -->
    @if (_isLoading)
    {
        <div class="text-center my-2">
            <div class="spinner-border" role="status">
                <span class="visually-hidden">Thinking...</span>
            </div>
            <div>Thinking...</div>
        </div>
    }

    <!-- Chat input -->
    <div class="chat-input">
        <textarea class="form-control" @bind="_userInput" placeholder="Type your message here..." rows="3"></textarea>
        <button class="btn btn-primary mt-2" @onclick="SendMessage" disabled="@_isLoading">Send</button>
    </div>
</div>

@code {
    private string _userInput = string.Empty;
    private string _selectedModel = "llama3.1:8b"; // default model selection
    private readonly List<ChatMessageDisplay> _chatHistory = new();
    private bool _isLoading = false;

    public class ChatMessageDisplay
    {
        public required string Role { get; init; }
        public required string Message { get; init; }
    }

    private async Task SendMessage()
    {
        if (string.IsNullOrWhiteSpace(_userInput))
        {
            return;
        }

        _chatHistory.Add(new ChatMessageDisplay { Role = "User", Message = _userInput });
    
        // Create a ChatPrompt that includes the full conversation history.
        ChatPrompt prompt = new ChatPrompt 
        { 
            Message = _userInput, 
            Model = _selectedModel,
            ConversationHistory = _chatHistory.Select(m => 
                new ChatMessage(
                    m.Role.Equals("User", StringComparison.OrdinalIgnoreCase) ? ChatRole.User : ChatRole.Assistant, 
                    m.Message)
            ).ToList()
        };

        _isLoading = true;
        try
        {
            // Call the ChatHistory endpoint on the API using the absolute URL which will be changed in the future to auto detect.
            HttpResponseMessage response = await Http.PostAsJsonAsync("http://localhost:5000/api/chat/chathistory", prompt);
            if (response.IsSuccessStatusCode)
            {
                List<ChatMessageDisplay>? messages = await response.Content.ReadFromJsonAsync<List<ChatMessageDisplay>>();
                if (messages != null && messages.Any())
                {
                    ChatMessageDisplay newAssistantMessage = messages.Last();

                    _chatHistory.Add(newAssistantMessage);
                }
            }
            else
            {
                // display most likely reason why it didn't work to user.
                _chatHistory.Add(new ChatMessageDisplay { Role = "SYSTEM", Message = "Docker image not running or selected LLM not installed." });

                await Console.Error.WriteLineAsync($"API error: {response.StatusCode}");
            }
        }
        catch (Exception ex)
        {
            await Console.Error.WriteLineAsync($"Exception calling API: {ex.Message}");
        }
        finally
        {
            _isLoading = false;
            _userInput = string.Empty;
        }
    }
}
